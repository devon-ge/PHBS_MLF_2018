# Grayscale image colorization

Course project of [Machine Learning for Finance](https://github.com/PHBS/2018.M1.MLF) at [PHBS](http://english.phbs.pku.edu.cn/). This project aims to realize automatic colorization of grayscale images. The
repository is where we develop algorithms. We welcome contributions if you are interested in our
project. For example, you can:

* [Submit bugs or issues](https://github.com/devon-ge/PHBS_MLF_2018/issues) to improve the performance of our model.
* [File pull requests](https://github.com/devon-ge/PHBS_MLF_2018/pulls) if you have better ideas.

## Team Members

* [Ge Desheng](https://github.com/devon-ge), student ID: 1701213756
* [Wang Yumeng](https://github.com/yumengwang123), student ID: 1701213112
* [Wu Gan](https://github.com/SuperWGAaron), student ID: 1701212974
* [Zhang Mingyu](https://github.com/myzhangcn), student ID: 1701213151

## Motivation

With the popularity of machine learning, a variety of applications are hoping to simplify
both our lives and jobs. The state-of-the-art machine learning methods in pattern recognition
enable humans to find the intrinsic relationship of things. For example, image recognition often
compares the gray scale of scanned picture with dataset for identificaiton. How to transform a
colorful picture to a grayscale one attracts attentions in algorithm research. This project, however,
intends to colorize a grayscale picture, i.e., regain the original image. We try to map grayscale to RGB
colors acorrding to gray scale distribution. Colorful pictures contains more
information (such as RGB pixels), thus contributing to better recognition. Also, we can apply this
colorization algorithm to repair old pictures.

![flowchart](test/flowchart.png)

## Data and preprocessing

We obtian images of natural landscape by a spider. The pictures are classified by principal components analysis (PCA). convert original images to standardized 256 by 256 Lab images. The model receives colorful images and load them in grayscale. The neuron network then trains paired samples.the input, and output colorized images.
We use PCA score of RGB to represent each picture and then use k-means to cluster those images. Each time we will pick one group to create the trainning and test set. Thus make sure trainning and test images are similar to a certain degree without the extra effort of classification by human.

### Images spider

Spider for this project are implemented under the [`Scrapy`](https://scrapy.org/) framework. Roughly speaking, a `Scrapy` project is nothing but a folder that contains auto-generated files (incluing `items.py`, `middlewares.py`, `pipelines.py` and `settings.py` under `PROJECT_NAME` folder, and spider(s) under `spiders` folder).

Among these, we mainly config in `items.py` and `settings.py`. [`items.py`](tooopen_img/tooopen_img/items.py) confines the crawling field (the spider only extract fields defined in this file). [`settings.py`](tooopen_img/tooopen_img/settings.py) contains project-specific configurations. More info on [Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html).

Pictures are crawled by the spider [`tooopen`](tooopen_img/tooopen_img/spiders/tooopen.py
) from the [nature category of **Toopen**](http://www.tooopen.com/img/87.aspx) (A website that posts categorized pictures). All pictures are name by the SHA1 hash of its url and stored in [`images/full`](images/full) directory (default of `Scrapy`).

To reproduce the crawling, just clone this repository and run spider `tooopen` via `Scrapy` command in terminal.

1. Clone this repository to your local disk

    `$ git clone https://github.com/devon-ge/PHBS_MLF_2018.git`

2. Change to `tooopen_img` directory (root directory of this scrapy project, should contain `scrapy.cfg` and this `README.md`)

    `$ cd PHBS_MLF_2018/tooopen_img`

3. Run `$ scrapy crawl tooopen[ -s CLOSESPIDER_ITEMCOUNT=60]`. The terminal should shows the logs of crawling requests/response.

Now, you can view the pictures in [`images/full`](images/full) (a folder automatically generated by
scrapy under a project's root directory).

**Notes**: In step 3, `60` is the maximum number of item requests (can be set per the demand).
The spider will keep running until all pictures are crawled if we
omit the `CLOSESPIDER_ITEMCOUNT` option. That's time consuming!

Below are some examples:

![example1](images/full/0a3f8ee9153997c651b82989799800d50a462dbd.jpg) ![example2](images/full/fb5f301c86b8e948cdb68a2e273fea24cdb8cdb1.jpg)

![example3](images/full/1d7de482b2f5359371ffd10a551ad07a3d86246b.jpg) ![example4](images/full/2d773493dc2415b631a66adc135e86c88e88fc03.jpg)

### A simple classifier

Once we get the data (images), we can start training the neuron network. To improve the accuray, we first build a classifier to classify pictures. For example, mountains and rivers pictures should be divided into separated groups. In this way, the model captures category-dependent features and thus should theoretically perform better than mixed training.

### Color channels conversion

By the implementation of `keras`, pictures are loaded in two channels (colorful and gray).  To reduce computational intensity and improve the efficiency of the model, the pictures are compressed. Below are details of the conversion processes.

* Convert the color channel of images from `RGB` to `Lab`. In `Lab` format, `L` is lightness, ranging from 0(black) to 100(white), `a` is the green/red channel, ranging from -128 to 127, and `b` is the blue/yellow channel, ranging from -128 to 127. The conversion from `RGB` to `Lab` is invertible. It is easier to train two color channels in Lab than three channels in RGB, and `a` and `b` are uncorrelated.

* The neuron network use the gray pictures as the input, and the colorful output. Both the input and output are compressed into 256 by 256 images.

:octocat:|Raw|Compressed (width=256 px)
---|---|---
Gray|![Raw picture](./test/example_Gray.jpg) | ![Compressed picture](./test/com_example_Gray.jpg)
RGB|![Raw picture](./test/example_RGB.jpg) | ![Compressed picture](./test/com_example_RGB.jpg)

* Images are divided into test sets and training sets by a certain proportion.

## Neural network training

The architecture of the convolutional neural network consists of two major parts:
1) The first part consists of a low-level feature extraction network, an intermediate feature extraction network, a fusion layer and a coloring network;
2) The second part consists of a low-level feature extraction network and a global feature extraction network.
Input grayscale images and use the convolutional neural network to train the model. Loss function is

![image](./test/equation.gif)

The first half of the above function is the unsupervised network loss function, and the second half is the classification part loss. If Alpha=0, only the color loss is considered.
